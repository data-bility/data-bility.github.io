---
title: Double Machine Learning (DML) — 인과추론과 머신러닝의 경계 위에서
date: 2025-06-30 00:00:00 +09:00
categories: [backgrounds]
math: true
---

> - 이 글은 SSG.COM의 가격최적화 모델 개발 과정에서 다루었던 **Double/Debiased Machine Learning (DML)** 개념을 복습하며,
> - "단순 예측"을 넘어 **처치(Treatment)의 인과적 효과**를 추정하기 위한 통계적 구조를 이해하기 위해 작성되었습니다.  
> - 실제로 EconML의 `CausalForestDML`을 적용하기 전에, 수식·가정·그래프 관점에서 DML의 원리를 다시 짚습니다.

---

## 1. Motivation — "예측"과 "효과 추정"의 경계

DML은 **“모델이 잘 맞는가?”(predictive accuracy)** 보다는 **“모델이 올바른 효과를 추정하고 있는가?”(causal validity)** 에 초점을 둡니다.

예를 들어, 할인율이 높아질수록 매출이 증가하는가? 이 질문은 단순 상관관계로는 답할 수 없습니다. <br>
가격, 노출량, 장바구니 수 등은 모두 매출에 영향을 미치는 동시에, 할인율(T) 자체에도 영향을 미치는 **confounder**이기 때문입니다.

DML은 이러한 교란(confounding)을 **‘잔차화(residualization)’** 방식으로 제거하고, 그 위에서 **X가 주어진 상황에서의 처치 효과(CATE : Conditional Average Treatment Effect)** 를 추정합니다.

---

## 2. 이론적 배경: Orthogonalization

### 2.1 기본 아이디어

관심 효과는 다음과 같이 표현됩니다.

$$
\tau(x) = \mathbb{E}[Y|do(T=t+\Delta), X=x] - \mathbb{E}[Y|do(T=t), X=x]
$$

여기서 $ T $는 처치(할인율), $ Y $는 결과(이익+매출), $ X $는 맥락적 특성(feature)입니다.

그러나 현실에서는 $ Y $와 $ T $가 단순히 독립이 아닙니다. <br>
교란 변수 $ W $가 둘 모두에 영향을 주는 경우, $ E[Y|T,X] $는 **인과적 의미**를 잃습니다.

이를 해결하기 위해, DML은 다음 두 개의 **보조 모델(nuisance model)** 을 학습합니다.

$$
\hat{m}(X,W) \approx E[Y|X,W], \quad \hat{e}(X,W) \approx E[T|X,W]
$$

그 후 잔차를 계산합니다.

$$
U_Y = Y - \hat{m}(X,W), \quad U_T = T - \hat{e}(X,W)
$$

이제 $ U_Y $와 $ U_T $의 관계는 confounder가 제거된 상태에서의 **순수한 인과 효과**를 반영합니다.

즉, 다음을 학습하면 됩니다.

$$
U_Y = \tau(X) \cdot U_T + \varepsilon
$$

이 때 $ \tau(X) $는 **Conditional Average Treatment Effect (CATE)**,  
즉, "이 상품(X)에 대해 할인율을 조정하면 Y가 얼마나 변하는가"를 의미합니다.

---

## 3. Double Machine Learning 구조

| 단계                | 역할 | 수식/설명                               |
|-------------------|------|-------------------------------------|
| 1. Nuisance 모델 적합 | confounder 제거 | $ \hat{m}(x,w), \hat{e}(x,w) $      |
| 2. 잔차화            | orthogonalization | $ U_Y, U_T $ 계산                     |
| 3. Main learner   | CATE 추정 | $ U_Y = \tau(X) U_T + \varepsilon $ |
| 4. Cross-fitting  | 과적합 보정 | fold 별로 서로 다른 표본 사용                 |
| 5. Aggregation    | 최종 효과 산출 | 평균 또는 개별 단위별 $ \tau(x) $            |

핵심은, **잔차화 + cross-fitting** 으로 $ m,e $의 예측오차가 효과 추정에 영향을 주지 않도록 하는 점입니다.

> - DML은 orthogonal score equation을 만족시킵니다.  
> - 즉, 1차 미분에서 bias가 0이 되어, nuisance 모델 오차가 $ \tau $ 추정에 2차 영향만 미칩니다.

---

## 4. 그래프 모델로 보는 DML

<img src="/assets/img/dml_example_background.png" width="8940px" height="250px" alt="dtw example_background">

왼쪽은 “현재 구조” — confounder $ Z $가 $ T,Y $ 모두에 영향을 줌.  
중앙은 “의심 구조” — mediator $ M $이 개입.  
오른쪽은 “개선 구조” — $ W(control) $, $ X(heterogeneity) $, $ M(mediator) $ 재분류.

**핵심 포인트:**
- $ Z $ (confounder) 는 $ W $로 묶어 control 처리
- $ M $ (mediator) 는 post-treatment 변수로 제거
- $ X $는 heterogeneity 기준 (forest split에 사용)

> 즉, “$ X $가 주어진 상황에서 $ T $만 조작했을 때 $ Y $가 얼마나 바뀌는가” 를 보기 위해, $ W $, $ X $, $ M $을 올바르게 재분류해야 한다.

---

## 5. 가정 점검 (Assumption Checklist)

(TO-DO) 아래 관련 가정들에 대해서도, 일반적인 통계 영역을 벗어나는 부분들이 있어서 개념을 명확히 정리 해둬야할 것 같다.

### (1) Unconfoundedness

$$ 
Y(t) \perp T \mid (X, W)
$$

- 관측 가능한 confounder를 최대한 \(X, W\)에 포함해야 한다.
- 누락된 교란은 refutation test나 A/B로 검정.

### (2) Overlap (Positivity)

$$
0 < P(T=t|X,W) < 1
$$

- 모든 구간에서 여러 수준의 할인율이 관측되어야 함.
- Overlap 부족 -> 외삽 편향.  
  -> `n_unique_prices`, `price_std`, `ntreat` 등의 필터 필요.

### (3) SUTVA(Stable Unit Treatment Value Assumption)
- 한 상품의 할인은 다른 상품의 결과에 영향을 주지 않는다.

### (4) Sample Size
- 분산 $ \propto 1/\sqrt{n} $, 샘플이 충분히 많아야 한다.

---

## 6. Practical Issues — 실무에서 겪은 혼란

1. **Mediator 혼입 문제**
  - 장바구니 수(cart_cnt), 클릭 수 같은 post-treatment 변수를 feature로 넣으면, RMSE는 낮아지지만 **인과적 해석**이 무너진다.

2. **$ R^2 $ 착시**
  - `forest.score()`로 나온 R²은 인과추론 품질 지표가 아니다. 인과모델의 품질은 refutation, overlap, policy value로 판단해야 한다.

3. **Overlap 결여**
  - 특정 카테고리는 거의 동일한 가격대만 존재 -> CATE 외삽이 발생한다. 데이터 전처리 단계에서 제거 필요.

4. **Absolute Effect 선택 문제**
  - $ |\tau| $를 argmax로 선택하면 **부호 정보가 손실**되어 “손해를 보는 할인”을 택할 수도 있다.

---

---

## 7. 코드 레벨에서의 구현 요약

```python
from econml.dml import CausalForestDML
from sklearn.linear_model import Lasso
from econml.sklearn_extensions.linear_model import WeightedLassoCV

# 1. 데이터셋 분할
X, Y, T, W = get_dataset(train_df)

# 2. 모델 선언
forest = CausalForestDML(
    model_y=Lasso(alpha=lambda_reg),
    model_t=WeightedLassoCV(),
    n_estimators=200,
    max_depth=10,
    min_samples_leaf=5,
    max_samples=0.15,
    n_jobs=32
)

# 3. tuning & fitting
forest.tune(Y, T, X=X, W=W)
forest.fit(Y, T, X=X, W=W)

# 4. 예측
tau_hat = forest.effect(X)
```
